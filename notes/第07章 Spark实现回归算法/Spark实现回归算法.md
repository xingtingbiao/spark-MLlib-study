Spark实现回归算法

目录: 
1. 回归分析概述                 2. 线性回归算法概述

3. 线性回归算法的原理           4. 最小二乘法

5. 随机梯度下降                 6. 实战Spark预测房价

7. 逻辑回归算法概述             8. 逻辑回归算法原理

9. 正则化原理                   10. 实战Spark逻辑回归

11. 保序回归算法概述            12. 保序回归算法原理

13. 实战一个保序回归数据分析






一. 回归分析概述 
  1) 回归分析介绍
    a. 回归与分类类似, 只不过回归的预测结果是<连续>的, 而分类的预测结果是<离散>的
    b. 这样, 也就使得很多回归与分类的模型可以经过改动而通用
    c. 正因如此, 对于回归和分类中基本原理相同的或类似的模型, 我们不再具体讲解
    

  2) Spark实现的回归算法
    a. Spark实现的回归算法很丰富, 有很多模型同样可以用于分类, 我们将在后面的分类中具体介绍. 
    其官方文档介绍如图所示: http://spark.apache.org/docs/2.3.3/mllib-classification-regression.html  --> Classification and regression






二. 线性回归算法概述
  1) 线性回归简介
    a. 在回归分析中, '自变量Y'与'因变量X'之间满足或基本满足<线性关系>, 可以使用线性模型进行拟合.
    b. 如回归分析中, 只有一个'自变量'的即为<一元线性回归>, 其自变量与因变量之间关系可以用一条直线近似表示.
    c. 同理, 对于多变量的回归称为<多元线性回归>, 其可以用一个平面或者超平面来表示.
  
  2) 使用线性回归的前提条件
    a. 自变量与因变量之间具有线性趋势, 我们在前面介绍过相关系数.
    b. 独立性: 因变量之间的取值相互独立, 不存在关联

  3) 线性回归的例子
    a. 例如探究沸点与气压的关系, 研究浮力与表面积之间的关系, 物理上经典的探索力与加速度之间的关系.






三. 线性回归算法的原理 
  1) 回顾机器学习模型
    a. 对于统计学习来讲, 机器学习模型就是一个函数表达式, 其训练过程就是在不断更新这个函数式的'参数', 
       以便这个函数能够对未知数据产生最好的预测结果.

    b. 机器学习的这个过程, 与人的学习过程原理是一样的, 都是先学习而后使用, 故归属于人工智能领域.

  2) 何为好的预测效果?
    a. 前面说 "以便达到最好的预测效果", 那么如何量化 "好的预测效果" 呢？
    b. 衡量预测效果好坏的函数称为<代价函数>(cost function), 或损失函数(loss function)
    例如: 用一个模型预测是否会下雨, 如果模型预测错误一天, 则损失函数加1, 那么机器学习算法的直接目标就是想方设法调节这个函数的参数,
          以便能够使预测错误的天数减少, 也就是降低损失函数值, 同时, 提供了预测的'准确率'

  3) 再谈线性回归
    a. 线性回归是最简单的数学模型之一.

    b. 线性回归的步骤是先用既有的数据, 探索自变量X与因变量Y之间存在的关系, 这个关系就是线性回归模型中的参数. 有了它, 
       我们就可以用这个模型对未知数据进行预测了.

    c. 机器学习的模型基本的训练过程亦是如此, 属于<监督学习>

  4) 线性回归模型
    a. 线性回归的数学表达式: 
                  y = w*x + b
                  y = wT * X
    b. 上式分别为一元线性回归与写成矩阵形式的线性回归模型







四. 最小二乘法






